<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}

	.center-col {
		display: flex;
		align-items: center;
		justify-content: center;
		text-align: center;
		flex-direction: column;
	}

	.center-row {
		display: flex;
		align-items: center;
		justify-content: center;
		text-align: center;
		flex-direction: row;
	}

	.bold {
		font-weight: bold;
	}
	
	.osu-sep {
		background-color: #BB0000;
		width: 100%;
		height: 3px;
	}

	.nav-link {
		color: white !important;
		font-weight: bold;
	}

	.navbar-brand {
		color: white !important;
		font-weight: bold;
	}

	.rotate-90 {
		transform: rotate(-90deg);
	}
</style>

<html>
<head>
	<title>pcaGAN: Improving posterior-sampling cGANs via principal component regularization</title>
	<meta property="og:title" content="pcaGAN: Improving posterior-sampling cGANs via principal component regularization" />
	<meta property="og:description" content="In ill-posed imaging inverse problems, there can exist many hypotheses that fit both the observed measurements and prior knowledge of the true image.  Rather than returning just one hypothesis of that image, posterior samplers aim to explore the full solution space by generating many probable hypotheses, which can later be used to quantify uncertainty or construct recoveries that appropriately navigate the perception/distortion trade-off. In this work, we propose a fast and accurate posterior-sampling conditional generative adversarial network (cGAN) that, through a novel form of regularization, aims for correctness in the posterior mean as well as the trace and K principal components of the posterior covariance matrix. Numerical experiments demonstrate that our method outperforms contemporary cGANs and diffusion models in imaging inverse problems like denoising, large-scale inpainting, and accelerated MRI recovery." />
	<script src="https://kit.fontawesome.com/a4b7107b9e.js" crossorigin="anonymous"></script>
	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN" crossorigin="anonymous">
</head>

<body>
	<nav class="navbar navbar-expand-lg navbar-light bg-light" style="background-color: #BB0000 !important;">
		<div class="container">
			<a class="navbar-brand" href="#">pcaGAN</a>
			<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
				<span class="navbar-toggler-icon"></span>
			</button>
			<div class="collapse navbar-collapse" id="navbarNav">
				<ul class="navbar-nav ml-auto" style="margin-left: auto;">
					<li class="nav-item">
						<a class="nav-link" href="#reg">Our Approach</a>
				  	</li>
				  <li class="nav-item">
					<a class="nav-link" href="#experiments">Experiments</a>
				  </li>
<!--				  <li class="nav-item">-->
<!--					<a class="nav-link" href="#inpaint">Inpainting</a>-->
<!--				  </li>-->
				  <li class="nav-item">
					<a class="nav-link" href="#paper">Paper</a>
				  </li>
				</ul>
			</div>
		</div>

	</nav>
	<div class="container">
		<div class="col center-col">
			<h2 class="m-0 mt-3 bold">pcaGAN: Improving posterior-sampling cGANs via principal component regularization</h2>
			<h3 class="m-0 mt-3">NeurIPS 2024</h3>
			<div class="row center-row mt-3" style="width: 100%;">
				<h4 class="pl-2 pr-2" style="display: inline; width: auto;">Matthew Bendel</h4>
				<h4 class="pl-2 pr-2" style="display: inline; width: auto;">Rizwan Ahmad</h4>
				<h4 class="pl-2 pr-2" style="display: inline; width: auto;">Philip Schniter</h4>
			</div>
			<img class="m-0 mt-3" src="resources/osu-logo-block.png" alt="Ohio State Logo" style="max-width: 300px;" />
			<div class="row center-row mt-3" style="font-size: 24px; width: 100%;">
				<a style="display: inline; width: auto;" href="https://openreview.net/pdf?id=Z0Nq3hHeEG" target="_blank" rel="noopener noreferrer">[<i class="fas fa-file-pdf" aria-hidden="true"></i> Paper]</a>
				<a style="display: inline; width: auto;" href="https://openreview.net/pdf?id=Z0Nq3hHeEG#page=13" target="_blank" rel="noopener noreferrer">[<i class="fas fa-file-pdf" aria-hidden="true"></i> Supplementary]</a>
				<a style="display: inline; width: auto;" href="resources/poster.pdf" target="_blank" rel="noopener noreferrer">[<i class="fas fa-file-image" aria-hidden="true"></i> Poster]</a>
				<a style="display: inline; width: auto;" href="https://github.com/matt-bendel/pcaGan" target="_blank" rel="noopener noreferrer">[<i class="fab fa-github" aria-hidden="true"></i> Code]</a>
			</div>
			<div class="osu-sep mt-5 mb-3"></div>
			<h2 class="m-0 bold">Abstract</h2>
			<p class="m-0 mt-3" style="text-align: left; font-size: 120%;">
				In ill-posed imaging inverse problems, there can exist many hypotheses that fit both the observed measurements and prior knowledge of the true image.
Rather than returning just one hypothesis of that image, posterior samplers aim to explore the full solution space by generating many probable hypotheses, which can later be used to quantify uncertainty or construct recoveries that appropriately navigate the perception/distortion trade-off.
In this work, we propose a fast and accurate posterior-sampling conditional generative adversarial network (cGAN) that, through a novel form of regularization, aims for correctness in the posterior mean as well as the trace and K principal components of the posterior covariance matrix.
Numerical experiments demonstrate that our method outperforms contemporary cGANs and diffusion models in imaging inverse problems like denoising, large-scale inpainting, and accelerated MRI recovery.
			</p>
			<div id="reg" class="osu-sep mt-5 mb-3"></div>
			<h2 class="m-0 bold">Our Main Contribution</h2>
			<p class="m-0 mt-3" style="text-align: left; font-size: 120%;">
				We extend our previous work, <a href="https://matt-bendel.github.io/rcGAN/" target="_blank">rcGAN</a>, and propose
				a new regularization for the <span style="font-weight: bold;">generator</span> that encourages correctness in the <span style="font-weight: bold;">\(K\)
				principal components</span> of the posterior covariance matrix,
				as well as the <span style="font-weight: bold;">posterior mean</span> and <span style="font-weight: bold;">posterior trace-covariance</span> when sampling the posterior. Our regularization is defined as
				<br/><br/>
				<span style="text-align: center; width: 100%; display: block;">
				\(\mathcal{R}(\boldsymbol{\theta}) = \mathcal{L}_{\sf rc}(\boldsymbol{\theta}) + \beta_{\sf pca}(\mathcal{L}_{\sf evec}(\boldsymbol{\theta}) + \mathcal{L}_{\sf eval}(\boldsymbol{\theta})) \),
				</span>
				<br/><br/>
				where \(\boldsymbol{\theta}\) are the generator's parameters, \(\mathcal{L}_{\sf rc}\) is rcGAN's regularization,
				and \(\mathcal{L}_{\sf evec}, \mathcal{L}_{\sf eval}\) encourages the generator's principal
				eigenvectors \(\{\hat{\boldsymbol{v}}_k\}_{k=1}^K\) and eigenvalues \(\{\hat{\lambda}_k\}_{k=1}^K\) to match those of the true covariance matrix:
				\(\{\boldsymbol{v}_k\}_{k=1}^K\) and \(\{\lambda_k\}_{k=1}^K\).
				Our approach outperforms existing cGANs and diffusion models on posterior sampling tasks like denoising, large-scale image completion, and accelerated MRI recovery,
				while sampling orders-of-magnitude faster than those diffusion models.
				<br />
				<br />
				We also demonstrate that pcaGAN recovers the posterior principal components more accurately than the <a href="https://eliasnehme.github.io/NPPC/" target="_blank">Neural Posterior Principal Components (NPPC)</a> method from Nehme et al., which directly
				estimates them.
			<h3 class="m-0 mt-3 bold">Eigenvector Regularization</h3>
			<p class="m-0 mt-3" style="text-align: left; font-size: 120%;">
				We define \(\mathcal{L}_{\sf evec}\) as
				<br/><br/>
				<span style="text-align: center; width: 100%; display: block;">
				\(\mathcal{L}_{\sf evec}(\boldsymbol{\theta}) = -\mathbb{E}_{\sf y}\big\{ \mathbb{E}_{\sf x,z_1,\dots,z_P|y}\big\{ \sum_{k=1}^K[\hat{\boldsymbol{v}}_k^\mathsf{T}(\boldsymbol{x}-\boldsymbol{\mu}_{\sf x|y})]^2 \big|\boldsymbol{y}\big\}\big\}\),
				</span>
				<br/><br/>
				where \(\boldsymbol{y}\) are our measurements, \(\boldsymbol{x}\) is the true image, \(\boldsymbol{\mu}_{\sf x|y}\) is the true posterior mean, and \(\{\hat{\boldsymbol{v}}_k\}_{k=1}^K\) are estimated posterior eigenvectors computed via and SVD of \(P=10K\) generator, \(G_{\boldsymbol{\theta}}\), posterior samples \(\{\hat{\boldsymbol{x}}_i:~\hat{\boldsymbol{x}}_i = G_{\boldsymbol{\theta}}(\boldsymbol{y}, \boldsymbol{z}_i)\}_{i=1}^P\) for \(\boldsymbol{z}_i\sim\mathcal{N}(\boldsymbol{0},\boldsymbol{I})\).
				If \(\boldsymbol{\mu}_{\sf x|y}\) was known, minimizing over \(\boldsymbol{\theta}\) would force \(\{\hat{\boldsymbol{v}}_k=\boldsymbol{v}_k\}_{k=1}^K\).
				Therefore, we approximate \(\boldsymbol{\mu}_{\sf x|y}\) as \(\boldsymbol{\mu}_{\sf x|y} \approx \hat{\boldsymbol{\mu}}_{\sf x|y} = \texttt{StopGrad}(\frac{1}{P}\sum_{i=1}^P\hat{\boldsymbol{x}}_i) \)
        		after \(\frac{1}{P}\sum_{i=1}^P\hat{\boldsymbol{x}}_i\) stabilizes with respect to validation PSNR.
			</p>
			<h3 class="m-0 mt-3 bold">Eigenvalue Regularization</h3>
			<p class="m-0 mt-3" style="text-align: left; font-size: 120%;">
				We define \(\mathcal{L}_{\sf eval}\) as
				<br/><br/>
				<span style="text-align: center; width: 100%; display: block;">
				\(\mathcal{L}_{\sf eval}(\boldsymbol{\theta})) = \mathbb{E}_{\sf y}\big\{ \mathbb{E}_{\sf x,z_1,\dots,z_P|y}\big\{ \sum_{k=1}^K\big(1 - \lambda_k/\hat{\lambda}_k\big) \big|\boldsymbol{y}\big\}\big\}\),
				</span>
				<br/><br/>
				where \(\{\lambda_k\}_{k=1}^K\) are the true principal posterior eigenvalues and \(\{\hat{\lambda}_k\}_{k=1}^K\) are the estimated posterior eigenvalues, computed from the same SVD as above.
				If \(\lambda_k\) was known, minimizing over \(\boldsymbol{\theta}\) would force \(\{\hat{\lambda}_k=\lambda_k\}_{k=1}^K\).
				Therefore, we approximate \(\lambda_k\) as \(\lambda_k \approx \texttt{StopGrad}(\tfrac{1}{P_{\mathsf{pca}}+1}\big\|\hat{\boldsymbol{v}}_k^\textsf{T}[\boldsymbol{x}-\hat{\boldsymbol{\mu}}_{\sf x|y},\hat{\boldsymbol{x}}_1-\hat{\boldsymbol{\mu}}_{\sf x|y},\dots,\hat{\boldsymbol{x}}_{P}-\hat{\boldsymbol{\mu}}_{\sf x|y}]\big\|_2^2)\)
        		after \(\{\hat{\boldsymbol{v}}_k\}_{k=1}^K\) stabilize, which is correct in expectation when \(\hat{\boldsymbol{v}}_k\) and \(\hat{\boldsymbol{\mu}}_{\sf x|y}\) are correct.
				<br/>
				<br/>
				Please see our <a href="resources/poster.pdf" target="_blank">poster</a> or our <a href="https://openreview.net/pdf?id=Z0Nq3hHeEG" target="_blank">paper</a> for more information!
			</p>
			</p>
			<div id="experiments" class="osu-sep mt-5 mb-3"></div>
			<h2 class="m-0 bold">Sample Eigenvectors for MNIST Digits</h2>
			<p class="m-0 mt-3" style=" text-align: left; font-size: 120%;">We used pcaGAN to denoise MNIST digits. Below, we show \(K=5\) principal covariance components, as well as \(\hat{\boldsymbol{\mu}}_{\sf x|y} \pm \alpha\hat{\boldsymbol{v}}_k\) for \(k\in\{1,4\}\) and \(\alpha\in\{-3,-2,0,2,3\}\). We compare with <a href="https://eliasnehme.github.io/NPPC/" target="_blank">NPPC</a>, which directly estimates the principal covariance components. For additional examples, please see our <a href="https://openreview.net/pdf?id=Z0Nq3hHeEG#page=13" target="_blank">supplementary material</a>.</p>
			<div class="row mt-3">
				<div class="col-lg-12">
					<p class="m-0 mt-3 mb-3" style="text-align: left; font-size: 110%;">
						pcaGAN's eigenvectors show much more meaningful structure.
					</p>
					<img class="m-0" src="resources/mnist_poster_fig.png" alt="MRI Reconstruction" style="width: 100%;"/>
				</div>
			</div>
			<div class="osu-sep mt-5 mb-3"></div>
			<h2 class="m-0 bold">Sample Reconstructions</h2>
			<p class="m-0 mt-3" style=" text-align: left; font-size: 120%;">We applied pcaGAN to multicoil MRI reconstruction and large-scale image completion with random masks. For additional examples, please see our <a href="https://openreview.net/pdf?id=Z0Nq3hHeEG#page=13" target="_blank">supplementary material</a>.</p>
			<div class="row mt-3">
				<div class="col-lg-6">
					<h5 style="padding-left: 10%;">MRI Reconstruction</h5>
					<p class="m-0 mt-3 mb-3" style="text-align: left; font-size: 110%;">
						Samples from our cGAN show meaningful variations (see arrows).
					</p>
					<img class="m-0" src="resources/mri_fig.png" alt="MRI Reconstruction" style="width: 100%;"/>
				</div>
				<div class="col-lg-6">
					<h5 style="padding-left: 10%;">Image Completion</h5>
					<p class="m-0 mt-3 mb-3" style="text-align: left; font-size: 110%;">
						Samples from our cGAN are both high quality and diverse.
					</p>
					<img class="m-0 mt-3" src="resources/inpaint_fig.png" alt="Inpainting Reconstruction" style="width: 100%;"/>
				</div>
			</div>
			<div id="paper" class="osu-sep mt-5 mb-3"></div>
			<h2 class="m-0 bold">Paper</h2>
			<h4 class="bold">pcaGAN: Improving posterior-sampling cGANs via principal component regularization</h4>
			<h5>Matthew Bendel, Rizwan Ahmad, Philip Schniter</h5>
			<div class="row row-center mt-3" style="width: 100%;">
				<!-- start arXiv -->
                <div class="col-3 center-col">
					<a href="https://arxiv.org/abs/2411.00605" target="_blank" rel="noopener noreferrer">
						<img alt="" class="layered-paper-big" style="height:100%; max-height: 175px; max-width: 200px;" src="./resources/paper.png">
					</a>
				</div>
				<!-- end arXiv -->

				<!-- start paper -->
                <div class="col-3 center-col">
					<a href="https://openreview.net/pdf?id=Z0Nq3hHeEG" target="_blank" rel="noopener noreferrer">
						<img alt="" class="layered-paper-big" style="height:100%; max-height: 175px;" src="./resources/paper.png">
					</a>
				</div>
				<!-- end paper -->

				<!-- start supp -->
                <div class="col-3 center-col">
					<a href="https://openreview.net/pdf?id=Z0Nq3hHeEG" target="_blank" rel="noopener noreferrer">
						<img alt="" class="layered-paper-big" style="height:100%; max-height: 175px;" src="./resources/supp.png">
					</a>
				</div>
				<!-- end supp -->

				<!-- start github -->
                <div class="col-3 center-col">
					<a href="https://github.com/matt-bendel/pcaGAN" target="_blank" rel="noopener noreferrer">
						<img alt="" id="github_logo" class="round" style="max-width:150px" src="./resources/github_logo.png">
					</a>
				</div>
				<!-- end github -->

            </div>
			<div class="row row-center mt-4" style="width: 100%;">
				<!-- start arXiv -->
                <div class="col-3 center-col">
					<p style="margin-top: 5px;"><a href="https://arxiv.org/abs/2411.00605" target="_blank" rel="noopener noreferrer">[<i class="ai ai-arxiv"></i> ArXiv]</a></p>
				</div>
				<!-- end arXiv -->

				<!-- start paper -->
                <div class="col-3 center-col">
					<p style="margin-top: 5px;"><a href="https://openreview.net/pdf?id=Z0Nq3hHeEG" target="_blank" rel="noopener noreferrer">[<i class="fas fa-file-pdf" aria-hidden="true"></i> Paper]</a></p>
				</div>
				<!-- end paper -->

				<!-- start supp -->
                <div class="col-3 center-col">
					<p style="margin-top: 5px;"><a href="https://openreview.net/pdf?id=Z0Nq3hHeEG#page=13" target="_blank" rel="noopener noreferrer">[<i class="fas fa-file-pdf" aria-hidden="true"></i> Supplementary]</a></p>
				</div>
				<!-- end supp -->

				<!-- start github -->
                <div class="col-3 center-col">
					<p style="margin-top: 5px;"><a target="_blank" rel="noopener noreferrer" href="https://github.com/matt-bendel/pcaGAN">[Code]</a></p>
				</div>
				<!-- end github -->

            </div>
			<div class="osu-sep mt-5 mb-3"></div>
			<h2 class="m-0 bold">Bibtex</h2>
			<pre class="command-copy mt-3" style=" display: block; text-align: left;
								background: #eee;
								white-space: pre;
								-webkit-overflow-scrolling: touch;
								max-width: 100%;
								min-width: 100px;
								border-radius: 10px;
								padding: 10;">@inproceedings{Bendel:NIPS:24,
	title={pca{GAN}: {I}mproving Posterior-Sampling {cGANs} via Principal Component Regularization},
	author={Bendel, Matthew and Ahmad, Rizwan, and Schniter, Philip},
	booktitle={Thirty-eigth Conference on Neural Information Processing Systems},
	year={2024},
	url={https://openreview.net/pdf?id=Z0Nq3hHeEG}
}</pre>

			<div class="osu-sep mt-5 mb-3"></div>
			<h3 class="bold m-0">Acknowledgements</h3>
			<p class="mb-5 mt-3" style="font-size: 11pt; text-align: left;">
				The authors are funded in part by the National Institutes of Health under grant R01-EB029957.<br>
				This webpage is based off the template that was originally made by <a target="_blank" rel="noopener noreferrer" href="http://web.mit.edu/phillipi/">Phillip Isola</a> and
				<a target="_blank" rel="noopener noreferrer" href="http://richzhang.github.io/">Richard Zhang</a> for a <a target="_blank" rel="noopener noreferrer" href="http://richzhang.github.io/colorization/">colorful</a> ECCV project;
				the code for the original template can be found <a target="_blank" rel="noopener noreferrer" href="https://github.com/richzhang/webpage-template">here</a>.<br>
				This site uses <a target="_blank" rel="noopener noreferrer" href="https://getbootstrap.com/">bootstrap</a> and <a target="_blank" rel="noopener noreferrer" href="https://fontawesome.com/">font awesome</a>.
				<br>
			</p>
		</div>
	</div>
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL" crossorigin="anonymous"></script>
</body>
</html>

